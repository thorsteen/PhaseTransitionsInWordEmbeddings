# PhaseTransitionsInWordEmbeddings
Ba project by Thor Larsen at Institute of Computer Science @ UCPH supervised by Daniel Hershcovich

McKinney-Bock and Bedrick (2019) and Hershcovich et al. (2019) found anecdotally that CBOW word embeddings with context window size 1 judge similarity better than those trained with larger windows, but then performance improves gradually until it recovers. This project aims to find out why this happens and what is changing in this transition by looking into the embeddings using similar natural language processing teqniques and explorative data analysis. Furthermore, the project aims to use similar cases as Hershcovich et al. (2019) and the word-2-vec algorithm.

Experiment is done using BlazingText Algortihm from AWS SageMaker.

# Tentative schedule:
   • 6 april reading
   • 6 may reproduce word2vec exp.
   • 14 may write background: word2vec
   • 20 may benchmark qualitative analysis
   • 1 june: write background benchmarks
   • 10 june testing characteristics hypotheses
   • 1 july writing results
   • 20 july first draft
   • 14 august submission
